{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8fae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "import numpy as np\n",
    "from skimage import io, transform\n",
    "import fnmatch\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "from sacred import Experiment\n",
    "from sacred.observers import FileStorageObserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76435dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_dir=\"Braille Dataset/\"):\n",
    "        # Initialization of data directory and list of all of the paths to each image in the data\n",
    "        self.data_dir = data_dir\n",
    "        self.image_path_list = sorted(self._find_files(data_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        '''\n",
    "        Function to get the length of the dataset\n",
    "        '''\n",
    "        return len(self.image_path_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        Function to be able to select images and corresponding labels from the dataset\n",
    "        '''\n",
    "        # Convert string labels to integers\n",
    "        labels = []\n",
    "        for path in self.image_path_list:\n",
    "            label = path.replace(self.data_dir + 'sorted_data/', '')[0]\n",
    "            labels.append(label)\n",
    "        labels = sorted(list(set(labels)))\n",
    "        labels2tensor = {label: labels.index(label) for label in labels}\n",
    "\n",
    "        image_path_ex = self.image_path_list[index]\n",
    "        label_ex = image_path_ex.replace(self.data_dir + 'sorted_data/', '')[0]\n",
    "        # Load image and transform it into a tensor as a grayscale image (since the images don't contain any colors other than black, white, gray)\n",
    "        image_ex = io.imread(image_path_ex)\n",
    "        # Normalize image (make values between 0 and 1)\n",
    "        image_ex = image_ex / np.max(image_ex)\n",
    "        transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),\n",
    "                                                    torchvision.transforms.ConvertImageDtype(dtype=torch.float32)])\n",
    "                                                    #, torchvision.transforms.Grayscale(num_output_channels=1)])\n",
    "        # Transform image and get label's corresponding integer\n",
    "        image_ex = transform(image_ex)\n",
    "        label_ex = labels2tensor[label_ex]\n",
    "\n",
    "        return image_ex, label_ex\n",
    "\n",
    "    def prep_data(self, data_dir):\n",
    "        '''\n",
    "        Function to organize the letter images into one directory for each letter\n",
    "        - this function assumes the dataset was downloaded and unzipped in the same directory as the python scripts\n",
    "        '''\n",
    "        os.makedirs(f'{data_dir}/sorted_data/', exist_ok=True)  # Creates a sorted_data directory within Braille Dataset directory\n",
    "        for root, dirs, files in os.walk(f'{data_dir}/Braille Dataset'):\n",
    "            for file in tqdm(sorted(files)):\n",
    "                if file.endswith('.jpg'):\n",
    "                    os.makedirs(f'{data_dir}/sorted_data/{file[0]}/',\n",
    "                                exist_ok=True)  # Adds a directory for each letter of the alphabet\n",
    "                    copyfile(f'{root}/{file}',\n",
    "                             f'{data_dir}/sorted_data/{file[0]}/{file}')  # Adds each letter image to it's corresponding directory\n",
    "\n",
    "    def _find_files(self, directory):\n",
    "        '''\n",
    "        Function to get all files in data directory\n",
    "        '''\n",
    "        image_path_list = []\n",
    "        sorted_dir = os.path.join(directory, \"sorted_data\")\n",
    "        if not os.path.isdir(sorted_dir):\n",
    "            print(\"Processing the data.\")\n",
    "            self.prep_data(self.data_dir)\n",
    "        for letter in string.ascii_lowercase:\n",
    "            curr_dir = os.path.join(sorted_dir, letter)\n",
    "            image_path_list += [os.path.join(curr_dir, f) for f in os.listdir(curr_dir)]\n",
    "        return image_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3c48de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassif(nn.Module):\n",
    "    \"\"\"Convolutional neural network classifier for Braille letter images\"\"\"\n",
    "    def __init__(self, num_channels1=16, num_channels2=32, num_channels3=64,\n",
    "                 num_lin_channels1=128, num_lin_channels2=64, num_classes=26):\n",
    "        super(CNNClassif, self).__init__()\n",
    "        # Convolutional channel values\n",
    "        self.num_channels1 = num_channels1\n",
    "        self.num_channels2 = num_channels2\n",
    "        self.num_channels3 = num_channels3\n",
    "        # Linear channel values\n",
    "        self.num_lin_channels1 = num_lin_channels1\n",
    "        self.num_lin_channels2 = num_lin_channels2\n",
    "        # Number of classes\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.cnn_layer1 = nn.Sequential(nn.Conv2d(3, num_channels1, kernel_size=5, padding=2), \n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(kernel_size=2))\n",
    "        self.cnn_layer2 = nn.Sequential(nn.Conv2d(num_channels1, num_channels2, kernel_size=5, padding=2), \n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(kernel_size=2))\n",
    "        self.cnn_layer3 = nn.Sequential(nn.Conv2d(num_channels2, num_channels3, kernel_size=3, padding=2), \n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool2d(kernel_size=2))\n",
    "        self.linear_layer1 = nn.Sequential(nn.Linear(num_channels3*4*4, num_lin_channels1), nn.ReLU())\n",
    "        self.linear_layer2 = nn.Sequential(nn.Linear(num_lin_channels1, num_lin_channels2), nn.ReLU())\n",
    "        self.linear_layer3 = nn.Sequential(nn.Linear(num_lin_channels2, num_classes), nn.ReLU())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        w = self.cnn_layer1(x)\n",
    "        y = self.cnn_layer2(w)\n",
    "        z = self.cnn_layer3(y)\n",
    "        #print(z.shape) # This shape will help you give correct input shape to linear_layer1\n",
    "        z2 = z.reshape(z.shape[0], -1)\n",
    "        lin1 = self.linear_layer1(z2)\n",
    "        lin2 = self.linear_layer2(lin1)\n",
    "        out = self.linear_layer3(lin2)\n",
    "        return out \n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "        m.bias.data.fill_(0.01)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076a1c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = Experiment('braille_cnn')\n",
    "ex.observers.append(FileStorageObserver('runs'))\n",
    "\n",
    "@ex.config\n",
    "def config():\n",
    "    \"\"\"Configuration of the Braille Image Classifier experiment.\"\"\"\n",
    "    seed = 0\n",
    "    batch_size = 8\n",
    "    num_epochs = 50\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    learning_rate = 0.01\n",
    "    patience = 10\n",
    "    num_channels1 = 32\n",
    "    num_channels2 = 64\n",
    "    num_channels3 = 128\n",
    "    num_lin_channels1 = 128\n",
    "    num_lin_channels2 = 64\n",
    "    \n",
    "    \n",
    "@ex.capture\n",
    "def training_cnn_classifier(model, train_dataloader, val_dataloader, num_epochs, loss_fn,\n",
    "                            learning_rate, patience, verbose=True):\n",
    "    model_tr = copy.deepcopy(model)\n",
    "    model_tr.train()\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model_tr.parameters(), lr=learning_rate)\n",
    "    \n",
    "    loss_all_epochs = []\n",
    "    no_improve = 0  # value to track for how many epochs validation accuracy is not improving\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        loss_current_epoch = 0\n",
    "        \n",
    "        for batch_index, (images, labels) in enumerate(train_dataloader):\n",
    "            \n",
    "            y_pred = model_tr.forward(images)\n",
    "            loss = loss_fn(y_pred, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_current_epoch += loss.item()\n",
    "\n",
    "        loss_all_epochs.append(loss_current_epoch / (batch_index + 1))\n",
    "        val_accuracy = eval_cnn_classifier(model_tr, eval_dataloader=val_dataloader)\n",
    "        # Early stopping implementation\n",
    "        if epoch == 0:\n",
    "            best_acc = val_accuracy\n",
    "        elif val_accuracy > best_acc:\n",
    "            best_acc = val_accuracy\n",
    "            torch.save(model_tr.state_dict(), 'test_model.pt')\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "        if verbose:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss_current_epoch/(batch_index + 1):.4f}')\n",
    "            print(f'-----> Validation Accuracy: {val_accuracy:.3f}%')\n",
    "            ex.log_scalar('loss', loss_current_epoch, step=epoch+1)\n",
    "\n",
    "        if no_improve >= patience:\n",
    "            break\n",
    "        \n",
    "    return model_tr, loss_all_epochs\n",
    "\n",
    "\n",
    "def eval_cnn_classifier(model, eval_dataloader):\n",
    "\n",
    "    model.eval() \n",
    "\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in eval_dataloader:\n",
    "            y_predicted = model(images)\n",
    "            _, label_predicted = torch.max(y_predicted.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (label_predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "@ex.automain\n",
    "def run(seed, batch_size, num_epochs,\n",
    "        num_channels1, num_channels2, num_channels3,\n",
    "        num_lin_channels1, num_lin_channels2):\n",
    "\n",
    "    # Instantiating the dataset\n",
    "    dataset = ImageDataset()\n",
    "    # Splitting the dataset\n",
    "    split_data = random_split(dataset, [1248, 156, 156], generator=torch.Generator().manual_seed(seed))\n",
    "    train_data, val_data, test_data = split_data\n",
    "\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    num_classes = len(list(set([datapoint[1] for datapoint in train_data])))\n",
    "    print(\"Number of classes: \", num_classes)\n",
    "    batch_data, batch_name =  next(iter(train_dataloader))\n",
    "    print(f'Batch shape [batch_size, image_shape]: {batch_data.shape}')\n",
    "    print('Number of batches:', len(train_dataloader))\n",
    "\n",
    "    print(\"== Initializing model...\")\n",
    "    model = CNNClassif(num_channels1, num_channels2, num_channels3,\n",
    "                       num_lin_channels1, num_lin_channels2, num_classes)\n",
    "    torch.manual_seed(seed)\n",
    "    model.apply(init_weights)\n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    ex.log_scalar('number_of_params', num_params)\n",
    "    print(model)\n",
    "\n",
    "    print(\"== Training...\")\n",
    "    model, loss_total = training_cnn_classifier(model, train_dataloader, val_dataloader)\n",
    "    # Best model is saved within training function\n",
    "    # torch.save(model.state_dict(), 'test_model.pt')\n",
    "    ex.add_artifact('test_model.pt')\n",
    "\n",
    "    # TO DO: make it prettier\n",
    "    plt.plot(loss_total)\n",
    "    plt.savefig('loss.png')\n",
    "    ex.add_artifact('loss.png')\n",
    "\n",
    "    print(\"== Evaluating...\")\n",
    "    # Instantiating our model and loading the best model checkpoint from training\n",
    "    model_eval = CNNClassif(num_channels1, num_channels2, num_channels3,\n",
    "                            num_lin_channels1, num_lin_channels2, num_classes)\n",
    "    model_eval.load_state_dict(torch.load('test_model.pt'))\n",
    "    accuracy = eval_cnn_classifier(model_eval, test_dataloader)\n",
    "    ex.log_scalar('accuracy', accuracy)\n",
    "    return f'{accuracy:.3f}%'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nn_labs]",
   "language": "python",
   "name": "conda-env-nn_labs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
